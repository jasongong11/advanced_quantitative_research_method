{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f660541f-cb8c-4982-b22d-1ed4439252b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "# Introduction to Linear Algebra for Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356a76d-f7d5-4517-a41b-48d900e97eb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Why Linear Algebra?\n",
    "\n",
    "Linear Algebra is critical for \n",
    "\n",
    "1. Multiple regression\n",
    "2. Advanced statistical methods\n",
    "3. Data manipulation\n",
    "4. Machine learning\n",
    "\n",
    "It provides efficient ways for:\n",
    "1. Expressing the computation\n",
    "2. Managing data in multi-dimensions\n",
    "3. Handling big data and executing the computation\n",
    "\n",
    "Linear algebra is probably the most important mathematical pre-requisite, and you will survive this :D "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c818a0-d283-4f97-958d-8aabb98b5591",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector\n",
    "\n",
    "A vector is an **ordered** list of numbers or random variables. \n",
    "\n",
    "It can be written as:\n",
    "\n",
    "| | |  |\n",
    "| --- | --- | --- |\n",
    "|$\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ \\end{bmatrix}$ | $\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\\\ \\end{pmatrix}$ | $(1, 2, 3)$|\n",
    "\n",
    "- The size of a vector is the number of elements in the list\n",
    "- Elements or entries are the items in the list\n",
    "- Vector of size $n$ is called $n$ vector\n",
    "- A single number is called a scalar and has size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a4176-d449-4890-a9a2-d2cff49cf250",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector notation\n",
    "\n",
    "- We use symbols to notate a vector, such as $\\vec{\\beta}, k, p, \\beta$ etc\n",
    "- The ith element of the vector $a$ is denoted as $a_i$. For instance $a = \\begin{bmatrix} 3 \\\\ 1 \\\\ 5 \\\\ \\end{bmatrix} = \\begin{bmatrix} a_1 \\\\ a_2 \\\\ a_3 \\\\ \\end{bmatrix}$, then $a_2 = 1$\n",
    "\n",
    "\n",
    "What is the size of the following vector? \n",
    "\n",
    "What is the 3rd entry of the vector?\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1.5 \\\\ 6 \\\\ 9 \\\\ -4 \\\\ 8 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe01ca-44e8-4c13-928a-2d3ebcbf9dec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector Space \n",
    "\n",
    "A $n$ vector can be represented as a point in a $n$ dimensional space or a vector from the orginal point to the point. \n",
    "\n",
    "For instance, a 2-vector $x=\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$ can be visualized as a point in the 2-dimensional space $(x_1, x_2)$ or a vector starting from the orginal point $(0,0)$ to the point $(x_1, x_2)$\n",
    "\n",
    "![vector](./img/vector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58024979-cb53-4a4c-ab6d-2a88bbd4371e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector Space \n",
    "\n",
    "A $n$-vector can be visualized in $n$ dimensional space.\n",
    "\n",
    "For instance, a 3-vector $\\begin{bmatrix} 2 \\\\ 3 \\\\ 5 \\end{bmatrix}$ can be represented as \n",
    "\n",
    "![vector](./img/vector_3d.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e268802-1a2d-48e0-a1ea-4c10dca205e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Use vector to represent data\n",
    "\n",
    "We may use vectors to represent data. For example:\n",
    "\n",
    "- One sample of multiple variables: representing color in (R, G, B), and red would be $[255 \\ 0 \\  0 ]$\n",
    "- Multiple samples of one single variable: price of stock $\\begin{bmatrix} 1.2 \\\\ 1.3 \\\\ 1.4 \\\\ 2 \\\\ 0.5 \\\\ -1\\end{bmatrix}$\n",
    "- Categorical variable: dummy coding variables\n",
    "- Countings of categories: word of bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce59a7-1569-4e38-b653-bb232d4028c2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector operations\n",
    "\n",
    "### Vector addition\n",
    "\n",
    "Vectors of the same size can be added, for instance, two vector $a = \\begin{bmatrix} 2 \\\\ 3 \\\\ 5 \\end{bmatrix}$ and $b =  \\begin{bmatrix} -1 \\\\ 4 \\\\ 7 \\end{bmatrix}$ can be added by simply adding each of their element together\n",
    "\n",
    "$$\n",
    "a + b = \\begin{bmatrix} 2-1 \\\\ 3+4 \\\\ 5+7 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 7 \\\\ 12 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Vector minus can do in the same way. \n",
    "\n",
    "Note that vectors of different size can not be added or minused. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c7da3-01fb-45af-97ae-0ed6b35ffa93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector addition rules\n",
    "\n",
    "The vector addition rules are very similar to the addition rules of scalers.\n",
    "\n",
    "1. $a + b = b + a$\n",
    "2. $a + (b + c) = (a + b) + c$\n",
    "3. $a + \\vec{0} = \\vec{0} + a = a$   Here $\\vec{0}$ is a vector of the same size of $a$ with all elements being $0$\n",
    "4. $a - a = \\vec{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e407a0d-6aa8-4db6-b244-afb5b8d80897",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector addition in vector space\n",
    "\n",
    "Vectors can be represented as displacement in the $n$-dimension. Two vectors can be added as the sum of their displacement. \n",
    "\n",
    "For instance, in the following case, $a+b$ can be represented as \n",
    "\n",
    "<div>\n",
    "<img src=\"./img/vector_addition_1.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9eabe5-bf35-4596-a8a2-24920436cade",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector transpose\n",
    "\n",
    "A vector can be a column vector $a = \\begin{bmatrix} 2 \\\\ 3 \\\\ 5 \\end{bmatrix}$ or it can be a row vector $b = [2 \\ 3\\ 5]$.\n",
    "\n",
    "When we do not specify the dimension of a vector, we assume it is a column vector. \n",
    "\n",
    "The operation that transforms a vector from a column vector to a row vector or vice versa is called **transpose**. \n",
    "\n",
    "$$\n",
    "a^T = b\n",
    "$$\n",
    "\n",
    "Row vectors are usually denoted as a transposed vector  $a^T = [2 \\ 3\\ 5]$, because we assume vectors are column vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44967957-1fc8-420e-be55-b2b8ecc31fa4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector scaler multiplication\n",
    "\n",
    "A vector can be multiplied by a scalar (a singular number). \n",
    "\n",
    "To do so, you need to multiply every element in the vector to the scalar number. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a &= 2 \\ \\ \\ \\ \\ \\ \\ \\ b = \\begin{bmatrix} 2 \\\\ 3 \\\\ 5 \\end{bmatrix}\n",
    "\\\\\n",
    "ab &= \\begin{bmatrix} 2*2 \\\\ 2*3 \\\\ 2*5 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ 6 \\\\ 10 \\end{bmatrix}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5c12e-e627-406c-b3e6-b0af4b76a030",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Rules of vector scaler multiplication\n",
    "\n",
    "For vector $a$ and $b$, and scalers $\\beta$ and $\\gamma$, we have rules for multiplication in a similar way to muplication rules of scalers\n",
    "\n",
    "1. $(\\beta \\gamma) a = \\beta(\\gamma a)$\n",
    "2. $(\\beta + \\gamma) a = \\beta a + \\gamma a$\n",
    "3. $\\beta(a+b) = \\beta a + \\beta b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67eb213-ac13-4d43-b324-0facc7ed5009",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector inner product\n",
    "\n",
    "Vectors of the same size $n$ can be multiplied as **inner product**. \n",
    "\n",
    "The $n$-vector $a$ and the $n$-vector $b$ can be multiplied as their inner product $<a, b>$, which is \n",
    "\n",
    "$$\n",
    "<a, b> = a^T b = a_1 b_1 + a_2 b_2 + a_3 b_3 + ... + a_n b_n = \\sum_{i=1}^n a_ib_i\n",
    "$$\n",
    "\n",
    "For instance the inner product of $a = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$ and $b = \\begin{bmatrix} 2 \\\\ 3 \\\\ 5 \\end{bmatrix}$ is \n",
    "\n",
    "$$\n",
    "<a, b> = a^T b = 1*2 + 2*3 + 3*5 = 23\n",
    "$$\n",
    "\n",
    "The inner product of a vector with itself is $a^Ta = \\sum_{i=1}^n a_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb6dc5-5210-43ca-b84a-3863c4869acb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector norm\n",
    "\n",
    "The **norm** of a vector $||a||$ can be considered as its length in the $n$ dimensional vector space, or the size of the vector. It is also called **magnitude** of the vector.\n",
    "\n",
    "$$\n",
    "||a|| = \\sqrt{a_1^2 + a_2^2 + ... + a_n^2} = \\sqrt{a^Ta}\n",
    "$$\n",
    "\n",
    "For instance, a norm for a vector $x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$ is the length of the vector and $||x|| = \\sqrt{x_1^2 + x_2^2}$\n",
    "\n",
    "![vector_norm](./img/vector.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e65f56-5bca-4dd2-a7b2-21a058f0fd32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Vector distance\n",
    "\n",
    "The Euclidean distance between two vectors $a$ and $b$ of the same size $n$ is \n",
    "\n",
    "$$dist(a,b) = ||a-b|| = \\sqrt{\\sum (a_i - b_i)^2}$$\n",
    "\n",
    "Consider the two $2$ dimensional vectors $a$ and $b$ being two points in the $2$ dimensional space, the distance can be represented by the displacement from $a$ to $b$ as $a-b$ or $b-a$\n",
    "\n",
    "![vector_distance](./img/vector_distance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da75d2-0547-40cf-b9af-13e112205c14",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vector inner product and angle\n",
    "\n",
    "The inner product of two $n$ vectors $a$ and $b$ can be represented as the product of the norms of the two vectors $||a||||b||$ and the cosine of the angle between the two vectors $\\angle(a,b) = \\theta$. \n",
    "\n",
    "$$\n",
    "a^T b = ||a|| ||b|| cos(\\theta)\n",
    "$$\n",
    "\n",
    "The angle between two vectors is critical to describe the relationship between two vectors as it will determine one type of dissimilarity between the two vectors. The smaller the angle between two vectors, the more similar these two vectors will be in the space. We can use the **cosine similarity** to describe this. \n",
    "\n",
    "$$\n",
    "cossimilarity(a, b) = cos(\\theta) = \\frac{a^Tb}{||a||||b||}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1685d6fd-5dbb-497f-a6ce-99036a9a9619",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "![cosine](./img/cosinesimilarity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79713247-6af2-4626-85d4-f3f00b8bfe8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Special relationship between vectors\n",
    "\n",
    "Depending on the angle between two vectors $a$ and $b$, there are some special relationships between the two vectors:\n",
    "\n",
    "1. Vectors with the same direction. $\\theta=0^{\\circ}$ \n",
    "   \n",
    "   $cos(\\theta) = 1$ thus $a^Tb = ||a|| ||b||$\n",
    "   \n",
    "2. Vectors that are orthogonal with each other, $\\theta = 90^{\\circ}$\n",
    "   \n",
    "   $cos(\\theta) = 0$ thus $a^Tb = 0$\n",
    "\n",
    "3. Vectors that are in opposite direction, $\\theta = 180^{\\circ}$\n",
    "   \n",
    "   $cos(\\theta) = -1$ thus $a^Tb = -||a|| ||b||$\n",
    "4. Vectors that are either in the same direction or in the opposite direction is called **linear dependent**, such that there exists constants $\\beta$ to make $a+\\beta b = 0$. Otherwise these two vectors are **linear independent**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd73ec-e403-447c-ab5a-93e263595bb5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vectors applied to data\n",
    "\n",
    "1. Linear regression line can be expressed as the inner product of the vector of indepdent variables and the vector of regression coefficients or slopes and intercept.\n",
    "   $$\n",
    "   \\begin{align}\n",
    "   Y_i = \\beta_0 * 1 + \\beta_1 X_{1,i} + \\beta_2 X_{2, i} + ... + \\beta_p X_{p, i}\\\\\n",
    "   Y_i = \\vec{X_i} ^T \\vec{\\beta}  \\ \\ \\ \\ \\text{where $\\vec{\\beta} = \\begin{bmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{bmatrix}$ and $\\vec{X_i} = \\begin{bmatrix} 1 \\\\ X_{1,i} \\\\ X_{2,i} \\end{bmatrix}$}\n",
    "   \\end{align}\n",
    "   $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef09e6-53de-4429-a2d6-7b9a94ee163d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Vectors applied to data\n",
    "\n",
    "2. the correlation coefficient between two variables $X$ and $Y$ can be expressed as the cosine similarity of the centered data vector $X' = X-\\bar{X}$ and $Y'= Y-\\bar{Y}$\n",
    "   $$\n",
    "   \\begin{align}\n",
    "   X = \\begin{bmatrix} X_1 \\\\ X_2 \\\\ ... \\\\ X_n \\end{bmatrix} \\ \\ \\ Y = \\begin{bmatrix} Y_1 \\\\ Y_2 \\\\... \\\\ Y_n \\end{bmatrix} \\ \\ \\ X' = \\begin{bmatrix} X_1-\\bar{X} \\\\ X_2-\\bar{X} \\\\ ... \\\\ X_n-\\bar{X} \\end{bmatrix} \\ \\ \\ Y' = \\begin{bmatrix} Y_1-\\bar{Y} \\\\ Y_2-\\bar{Y} \\\\ ... \\\\ Y_n-\\bar{Y} \\end{bmatrix}\n",
    "   \\\\\n",
    "   r(X, Y) = \\frac{\\sum(X_i-\\bar{X})(Y_i-\\bar{Y})}{\\sqrt{\\sum(X_i-\\bar{X})^2}\\sqrt{\\sum(Y_i-\\bar{Y})^2}} = \\frac{(X-\\bar{X})^T(Y-\\bar{Y})}{||X-\\bar{X}|| ||Y-\\bar{Y}||} = cos(\\angle(X', Y'))\n",
    "   \\end{align}\n",
    "   $$\n",
    "\n",
    "3. When the two vectors of two variables are orthogonal with $cos(\\theta)=0$, the correlation between them is 0. When two variables are linearly independent and the two variables are mean-centered, we can call them **orthogonal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf5de5-b3a8-40d4-abb6-4052bcd11ac8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Exercise\n",
    "\n",
    "For two random variables $X$ and $Y$, a sample of size $n=3$, we write these two random samples as vector $X$ and $Y$:\n",
    "\n",
    "$$\n",
    "X=\\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ Y=\\begin{bmatrix} -1 \\\\ -2 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "1. Drawing these two vectors in a 3-dimensional space\n",
    "2. Compute the a linear transformation of $X$ and $Y$ as $Z = 0.5 X + 1Y$\n",
    "3. Drawing the new vector $Z$ in the 3-dimensional space\n",
    "4. Compute the norm (length) of these two vectors $||X||$ and $||Y||$\n",
    "5. Compute the inner product between these two vectors $X^T Y$\n",
    "6. Compute the sum of these two vectors and the displacement between these two vectors $X+Y$ and $X-Y$\n",
    "7. Compute the Euclidean distance between these two vectors $||X-Y||$\n",
    "8. Compute the Cosine similarity between these two vectors $cos(\\angle{(X,Y)}) = \\frac{X^TY}{||X||||Y||}$\n",
    "9. Compute the centered vector $X' = X-\\bar{X}$ and $Y'=Y-\\bar{Y}$\n",
    "10. Compute the correlation coefficient between $X$ and $Y$ as $r(X, Y) = \\frac{X'^T Y'}{||X'||||Y'||}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd032e9-3a0a-4604-a7c3-d4f56187e7fa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "# Matrix\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/matrix_movie.avif\" width=\"700\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1749c53-fc60-4a9a-8479-2dbb6ee20ca6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix\n",
    "\n",
    "A **matrix** is an array of numbers, such as\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "4 & -1 & 3 & 2 \\\\\n",
    "3 & 9 & 1 & 4 \\\\\n",
    "1 & 2 & 0 & 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We usually use the bolded uppercase letter to denote a matrix $\\boldsymbol{A}$, and use a lowercase letter with index $a_{i,j}$ to indicate entries in the matrix.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} \n",
    "a_{11} & a_{12} & a_{13} & a_{14} \\\\\n",
    "a_{21} & a_{22} & a_{23} & a_{24} \\\\\n",
    "a_{31} & a_{32} & a_{33} & a_{34}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a191fe6-0057-4436-9170-80c391cf0090",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix Order\n",
    "\n",
    "A matrix $\\boldsymbol{A}$ with $U$ rows and $V$ columns is said to have **order** $U \\times V$. \n",
    "\n",
    "An element $a_{ij}$ refers to the element in the $i$th row and $j$th column. \n",
    "\n",
    "This can be denoted as \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\{a_{ij}\\}_{U \\times V}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018c7f7-efac-4071-bbbb-8080b8614869",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix, vectors, and scalers\n",
    "\n",
    "A matrix of size $U \\times V$ consists of $U$ rows and $V$ columns. These rows can be considered as row vectors, and columns can be considered as column vectors. \n",
    "\n",
    "A $U$ - vector can be considered a matrix of size $U \\times 1$, and its transpose can be considered a matrix of size $1 \\times U$.\n",
    "\n",
    "A scaler can be considered as a matrix of size $1 \\times 1$.\n",
    "\n",
    "So, vectors and scalers can be considered as matrices. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{3 \\times 2} = \\begin{bmatrix} \n",
    "a_{11} & a_{12} \\\\\n",
    "a_{21} & a_{22} \\\\\n",
    "a_{31} & a_{32}\n",
    "\\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ x_{3 \\times 1} = \\begin{bmatrix} \n",
    "x_{11} \\\\\n",
    "x_{21} \\\\\n",
    "x_{31}\n",
    "\\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ a_{1 \\times 1} = [a_{11}]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08178f3e-ac49-4fa3-ad83-d66e70274c97",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Special Matrix\n",
    "\n",
    "There are a list of matrices that are special and important to know. \n",
    "\n",
    "1. Square matrix: Square matrices have the same number of rows and columns.\n",
    "   $$\n",
    "   \\boldsymbol{X}_{3 \\times 3} = \\begin{bmatrix} \n",
    "    a_{11} & a_{12} & a_{13} \\\\\n",
    "    a_{21} & a_{22} & a_{23} \\\\\n",
    "    a_{31} & a_{32} & a_{33} \\end{bmatrix}\n",
    "   $$\n",
    "2. Symmetric matrix: Symmatric matrices are matrices that are symmetric in a way such that $x_{ij} = x_{ji}$\n",
    "   $$\n",
    "   \\boldsymbol{X}_{3 \\times 3} = \\begin{bmatrix} \n",
    "    1 & 4 & 5 \\\\\n",
    "    4 & 2 & 7 \\\\\n",
    "    5 & 7 & 3 \\end{bmatrix}\n",
    "   $$\n",
    "3. Null matrix: Null matrices $\\boldsymbol{\\emptyset}$ are matrices that all entries are 0.\n",
    "   $$\n",
    "   \\boldsymbol{\\emptyset}_{3 \\times 4} = \\begin{bmatrix} \n",
    "    0 & 0 & 0 & 0 \\\\\n",
    "    0 & 0 & 0 & 0\\\\\n",
    "    0 & 0 & 0 & 0\\end{bmatrix}\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d69f8-940f-4aee-9937-7edb1fc80d67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Special Matrix\n",
    "4. $1$ matrix: Matrics $\\boldsymbol{E}$ are matrices that all entries are 1.\n",
    "   $$\n",
    "   \\boldsymbol{E}_{3 \\times 4} = \\begin{bmatrix} \n",
    "    1 & 1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1\\end{bmatrix}\n",
    "   $$\n",
    "5. Diagonal matrix: Diagonal matrices $\\boldsymbol{D}$ are matrices that is square with 0 in all of the off-diagonal entries.\n",
    "   $$\n",
    "   \\boldsymbol{D}_{3 \\times 3} = \\begin{bmatrix} \n",
    "    1 & 0 & 0\\\\\n",
    "    0 & 4 & 0\\\\\n",
    "    0 & 0 & 7\\end{bmatrix}\n",
    "   $$\n",
    "6. Identity matrix: Identity matrices $\\boldsymbol{I}$ are matrices that is diagonal matrices with diagonal entries being all 1.\n",
    "   $$\n",
    "   \\boldsymbol{I}_{3 \\times 3} = \\begin{bmatrix} \n",
    "    1 & 0 & 0\\\\\n",
    "    0 & 1 & 0\\\\\n",
    "    0 & 0 & 1\\end{bmatrix}\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a57e8-a672-44c2-b5dc-07524a039012",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix linear independence\n",
    "\n",
    "A matrix $\\boldsymbol{A}_{U \\times V}$ can be considered as $V$ rows of $U$ vectors $\\vec{a}_1$, $\\vec{a}_2$, ..., $\\vec{a}_v$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{U \\times V} = \\begin{bmatrix} \n",
    "    a_{11} & a_{12} & ... & a_{1v} \\\\\n",
    "    a_{21} & a_{22} & ... & a_{2v} \\\\\n",
    "    ... & ... & ... & ... \\\\\n",
    "    a_{u1} & a_{u2} & ... & a_{uv} \\end{bmatrix} = \\begin{bmatrix} \n",
    "    \\vec{a}_1 & \\vec{a}_2 & ... & \\vec{a}_v \\end{bmatrix} \\ \\ \\ \\ \\ \\text{where} \\ \\ \\ \\vec{a_j} = \\begin{bmatrix} \n",
    "    a_{1j} \\\\ a_{2j} \\\\ ... \\\\ a_{uj} \\end{bmatrix}\n",
    "   $$\n",
    "\n",
    "For the set of the column vectors in the matrix, this matrix is called **linear dependent** if there exists constants $\\beta_1$, $\\beta_2$, ..., $\\beta_v$, such that not all $\\beta_i$ are 0, and\n",
    "\n",
    "$$\n",
    "\\beta_1 \\vec{a_1} + \\beta_2 \\vec{a_2} + ... \\beta_v \\vec{a_v} = 0\n",
    "$$\n",
    "\n",
    "In other words, at least one column vector in the matrix can be a linear combination of other vectors in the matrix. \n",
    "\n",
    "Otherwise, the matrix is called **linear independent**.\n",
    "\n",
    "We can also call this set of $v$ linear independent vectors as a **basis**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b6d3d-e8a3-4525-9c9d-cb21cd91b684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Orthogonal and orthonormal matrix\n",
    "For a linear independent matrix, if every column vector is orthogonal to each other $\\vec{a_i}^T \\vec{a_j}=0$ for $i \\ne j$, then we call this matrix an orthogonal matrix. \n",
    "\n",
    "If the norm of every column vector in the matrix equals 1,  $||\\vec{a_i}|| = 1$, and each column vector is orthogonal to each other, then we call this matrix an **orthonormal matrix**, or an **orthonormal basis**.  \n",
    "\n",
    "For instance, the matrix $\\boldsymbol{T}$ is an orthonormal basis. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{T} = \\begin{bmatrix} \n",
    "1/\\sqrt{3} & 1/\\sqrt{3} & 1/\\sqrt{3} \\\\\n",
    "1/\\sqrt{2} & -1/\\sqrt{2} & 0\\\\\n",
    "-1/\\sqrt{6} & -1/\\sqrt{6} & 2/\\sqrt{6}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ac68f-3d3b-4e6d-b3b5-a9d654ab3914",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Representing Data with Matrix\n",
    "\n",
    "Matrices are commonly used to represent data. For instance\n",
    "\n",
    "- A dataset with $p$ variables and $N$ samples will be represented as a $N \\times p$ matrix\n",
    "\n",
    "![matrix](./img/data_matrix.ppm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7be25-c0a4-4fbf-b824-347e5599418c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Image dataset\n",
    "\n",
    "![matrix](./img/image_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af183fd-f074-4381-a9a2-58aa7e7d9706",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Correlation matrix\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"./img/correlation_matrix.png\" width=\"700\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6613f-46f0-42b2-b625-f91550128e55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix Operations\n",
    "\n",
    "Similar to the operations we can do to vectors, we can also do them to matrices. \n",
    "\n",
    "We will walk them one by one in the following:\n",
    "\n",
    "### Matrix transpose\n",
    "\n",
    "Matrix **transpose** is to interchange the columns and rows for the matrix. For instance\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{3 \\times 2} = \\begin{bmatrix} \n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol{A}^T_{2\\times 3} = \\begin{bmatrix} \n",
    "1 & 3 & 5 \\\\\n",
    "2 & 4 & 6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The transpose of a matrix of size $U \\times V$ will have size $V \\times U$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{B}= \\boldsymbol{A}^T \\ \\ \\ \\ \\text{then} \\ \\ \\ \\ \\ b_{ij} = a_{ji}\n",
    "$$\n",
    "\n",
    "If $\\boldsymbol{A}$ is symmetric, then $\\boldsymbol{A}^T = \\boldsymbol{A}$, and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96561bb0-bac4-45fd-8e0a-96c42a256c74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Matrix trace\n",
    "\n",
    "For a square matrix $\\boldsymbol{A}_{U \\times U}$, the **trace** of this matrices is the sum of its diagonal entries.\n",
    "\n",
    "$$\n",
    "tr(\\boldsymbol{A}_{U \\times U}) = \\sum_{i=1}^U a_{ii}\n",
    "$$\n",
    "\n",
    "$$\n",
    "tr(\\begin{bmatrix} \n",
    "1 & 2 & 3 \\\\\n",
    "4 & 5 & 6 \\\\\n",
    "7 & 8 & 9 \\end{bmatrix}) = 1+5+9 = 15\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b466eaa-8fa0-48f3-817b-9fb500cbb8da",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix Addition\n",
    "\n",
    "Matrix **addition** can be applied to matrices with the same order/size. If two matrices have different order, they can not be added. \n",
    "\n",
    "When applying matrix addition, simply add each entry at the same position for both matrices. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{U \\times V} + \\boldsymbol{B}_{U \\times V} = \\boldsymbol{C}_{U \\times V} \\ \\ \\ \\ \\ \\ \\ a_{ij} + b_{ij} = c_{ij}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \\end{bmatrix} + \\begin{bmatrix} \n",
    "-1 & 5 \\\\\n",
    "4 & 2 \\\\\n",
    "9 & 0 \\end{bmatrix} = \\begin{bmatrix} \n",
    "1-1 & 2+5 \\\\\n",
    "3+4 & 4+2 \\\\\n",
    "5+9 & 6+0 \\end{bmatrix} = \\begin{bmatrix} \n",
    "0 & 7 \\\\\n",
    "7 & 6 \\\\\n",
    "14 & 6 \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb47a6f-e3e8-4dac-aa61-c53008cc565d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix addition rules\n",
    "\n",
    "For matrix addition, we will have \n",
    "\n",
    "1. $\\boldsymbol{A} + \\boldsymbol{B} = \\boldsymbol{B} + \\boldsymbol{A}$\n",
    "2. $\\boldsymbol{A} + (\\boldsymbol{B} + \\boldsymbol{C}) = (\\boldsymbol{A} + \\boldsymbol{B}) + \\boldsymbol{C}$\n",
    "3. $(\\boldsymbol{A}^T)^T = \\boldsymbol{A}$, $(\\boldsymbol{A}+\\boldsymbol{B})^T = \\boldsymbol{A}^T + \\boldsymbol{B}^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89a873-20c7-477e-8fe5-9b83be489b43",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Matrix scaler multiplication\n",
    "\n",
    "Similar to vector scaler multiplication, matrix scaler multiplication will multiply each entry in the matrix with the scaler. \n",
    "\n",
    "$$\n",
    "c \\boldsymbol{A}_{U \\times V} = c\\begin{bmatrix} \n",
    "a_{11} & ... & a_{1v} \\\\\n",
    "... & ... & ... \\\\\n",
    "a_{u1} & ... & a_{uv} \\\\ \\end{bmatrix} = \\begin{bmatrix} \n",
    "ca_{11} & ... & ca_{1v} \\\\\n",
    "... & ... & ... \\\\\n",
    "ca_{u1} & ... & ca_{uv} \\\\ \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5e103-e2ab-4983-b8e0-7a63c4c32383",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "Matrices ($\\boldsymbol{A}_{U \\times V}$ and $\\boldsymbol{B}_{V \\times W}$) can be multiplied only when the number of columns of the left matrix is equal to the the number of rows of the right matrix, otherwise they can not be multiplied together. \n",
    "\n",
    "The result of the matrix multiplication (if mutipliable) will have the number of rows equal to the number of rows of the left matrix, and have the number of columns equal to the number of columns in the right matrix. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{U \\times V} \\boldsymbol{B}_{V \\times W} = \\boldsymbol{C}_{U \\times W}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{2 \\times 3} \\boldsymbol{B}_{3 \\times 4} = \\boldsymbol{C}_{2 \\times 4} \\ \\ \\ \\ \\ \\ \\ \\text{Multipliable}\n",
    "$$\n",
    "$$\n",
    "\\boldsymbol{A}_{3 \\times 5} \\boldsymbol{B}_{3 \\times 3} \\ \\ \\ \\ \\ \\ \\ \\text{Not Multipliable}\n",
    "$$\n",
    "$$\n",
    "\\boldsymbol{A}_{1 \\times 10} \\boldsymbol{B}_{10 \\times 1} = \\boldsymbol{C}_{1 \\times 1} \\ \\ \\ \\ \\ \\ \\ \\text{Multipliable}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82224a31-888e-44e3-804d-6acc868154dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "The result multiplication matrix $\\boldsymbol{C} = \\boldsymbol{A}  \\boldsymbol{B}$ will have each entry $c_{ij}$ being the inner product of the $i$th row of the left matrix and the $j$the column of the right matrix. \n",
    "\n",
    "$$\n",
    "c_{ij} = \\vec{A_i^T} \\vec{B_j} = \\sum_{k=1}^V a_{ik}b_{kj}\n",
    "$$\n",
    "\n",
    "![multiply](./img/multiply_matrices.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739b0f50-dcb1-4325-86ab-b1e67c6298a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix multiplication practice\n",
    "\n",
    "For the multiplication the matrix multiplication $\\boldsymbol{C} = \\boldsymbol{A} \\boldsymbol{B}$\n",
    "\n",
    "1. Is this multipliable?\n",
    "2. What is the order/size of $\\boldsymbol{C}$ ?\n",
    "3. Calculate $\\boldsymbol{C}$.\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}_{3 \\times 2} = \\begin{bmatrix} \n",
    "1 & 4 \\\\\n",
    "3 & 1 \\\\\n",
    "-1 & 0 \\end{bmatrix} \\ \\ \\ \\  \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol{B}_{2 \\times 4} = \\begin{bmatrix} \n",
    "-1 & 2 & 0 & 1\\\\\n",
    "1 & 0 & 1 & 4 \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a059139-f013-4326-b2c6-9745a2fb46cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "### Rules for matrix multiplication\n",
    "1. $\\boldsymbol{A}\\boldsymbol{B} \\neq \\boldsymbol{B}\\boldsymbol{A}$\n",
    "2. $\\boldsymbol{A}(\\boldsymbol{B}+ \\boldsymbol{C}) = \\boldsymbol{A}\\boldsymbol{C}+\\boldsymbol{A}\\boldsymbol{B}$\n",
    "3. $\\boldsymbol{A}(\\boldsymbol{B}\\boldsymbol{C})=(\\boldsymbol{A}\\boldsymbol{B})\\boldsymbol{C}$\n",
    "4. $(\\boldsymbol{A}\\boldsymbol{B})^T = \\boldsymbol{B}^T \\boldsymbol{A}^T$,  $(\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C})^T = \\boldsymbol{C}^T \\boldsymbol{B}^T\\boldsymbol{A}^T$, ...\n",
    "5. $\\boldsymbol{A}\\boldsymbol{I} = \\boldsymbol{A}$ if multipliable, and similarly $\\boldsymbol{I}\\boldsymbol{A} = \\boldsymbol{A}$ if multipliable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5279e4-f3b6-4cc2-8fa9-5429a776893b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrices as linear transformation\n",
    "\n",
    "Any $U \\times V$ matrix $\\boldsymbol{A}$ can be considered as linearly transforming a $V \\times 1$ vector $x$ to another $U \\times 1$ vector $y$.\n",
    "\n",
    "$$\n",
    "y_{U \\times 1} = \\boldsymbol{A}_{U \\times V} x_{V\\times 1}\n",
    "$$\n",
    "\n",
    "For instance, if we want to transform a vector of samples for random variable $X$ as $x_{N \\times 1}$ to a scaler of sample mean $\\bar{X}_{1 \\times 1}$.\n",
    "\n",
    "We can do the following.\n",
    "\n",
    "$$\n",
    "[\\frac{1}{N}\\ ...\\ \\frac{1}{N}]_{1 \\times N}\n",
    "\\begin{bmatrix} \n",
    "x_1 \\\\\n",
    "... \\\\\n",
    "x_N \\end{bmatrix}_{N \\times 1} = \\frac{1}{N}\\sum x_i = \\bar{X}_{1\\times 1}\n",
    "$$\n",
    "\n",
    "In this case the matrix $[\\frac{1}{N}\\ ...\\ \\frac{1}{N}]_{1 \\times N}$ is the matrix that apply the linear transformation of the vector $x_{N\\times 1}$ to the vector $\\bar{X}_{1\\times 1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673f099-1e6a-40eb-992d-8e530691d9ce",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Quadratic Forms\n",
    "\n",
    "Given a symmetric matrix $\\boldsymbol{A}_{U \\times U}$ and a $U$ vector $x$, a **quadratic form** is defined as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x^T \\boldsymbol{A} x &= \\sum_{i=1}^{U}\\sum_{j=1}^V a_{ij} x_ix_j\n",
    "\\\\\n",
    "&= a_{11}x_1^2 + a_{22}x_2^2 + a_{33}x_3^2 + ... + a_{UU}x_U^2 + 2a_{12}x_1x_2 + 2a_{13}x_1x_3 + ... + 2a_{(U-1)U}x_{U-1}x_U\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If $x^T \\boldsymbol{A} x > 0$ for any $x$ except the 0 vector, $\\boldsymbol{A}$ is said to be **positive definite**\n",
    "\n",
    "If $x^T \\boldsymbol{A} x \\ge 0$ for any $x$ except the 0 vector, $\\boldsymbol{A}$ is said to be **positive semi-definite**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8ba2c0-ee92-4e20-b3ed-b0edd3941d70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix Inverse\n",
    "\n",
    "Matrix inverse is one of the most important operation on a matrix. \n",
    "\n",
    "What is an inverse? \n",
    "\n",
    "Inverse of a number $x$ is denoted as $x^{-1}$ which is  simple $x^{-1} = \\frac{1}{x}$, and we would have $xx^{-1}=1$.\n",
    "\n",
    "What is the inverse of a matrix $\\boldsymbol{A}^{-1}$? It must hold the property such that $\\boldsymbol{A}^{-1}\\boldsymbol{A}=\\boldsymbol{I}$ and $\\boldsymbol{A}\\boldsymbol{A}^{-1}=\\boldsymbol{I}$, where $\\boldsymbol{I}$ is the identity matrix. Note that non-square matrices do not have inverse. \n",
    "\n",
    "For instance\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "1 & 3 \\\\\n",
    "2 & 1 \\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol{A}^{-1} = \\begin{bmatrix} \n",
    "-1/5 & 3/5 \\\\\n",
    "2/5 & -1/5 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now verify that $\\boldsymbol{A}\\boldsymbol{A}^{-1} = \\boldsymbol{I}$ and $\\boldsymbol{A}^{-1}\\boldsymbol{A} = \\boldsymbol{I}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75be8e-d18c-4b8b-b599-83452b088e6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix Inverse\n",
    "\n",
    "Some times, $\\boldsymbol{A}^{-1}$ may not exists. When this is the case, the matrix $\\boldsymbol{A}$ is said to be **singular** or **non-invertible**. \n",
    "\n",
    "If $\\boldsymbol{A}^{-1}$ exists, then the matrix $\\boldsymbol{A}$ is said to be **invertible** or **non-singular**\n",
    "\n",
    "How do we determine if a matrix is invertible or not? \n",
    "\n",
    "We need to calculate **determinant** of the matrix $det(\\boldsymbol{A})$ or $|\\boldsymbol{A}|$. \n",
    "\n",
    "Such that if $|\\boldsymbol{A}| = 0$ then $\\boldsymbol{A}$ is non-invertible, and if $|\\boldsymbol{A}| \\neq 0$ then $\\boldsymbol{A}$ is invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3fa34-b8cd-42e5-b06b-2c2ce4f94c5f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix determinant\n",
    "\n",
    "Each square matrix $\\boldsymbol{A}_{U \\times U}$ has a determinant $det(\\boldsymbol{A})$.\n",
    "\n",
    "How do we calculate determinant? \n",
    "\n",
    "It is simple for a $2 \\times 2$ matrix. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "a & b \\\\\n",
    "c & d \\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ det(\\boldsymbol{A}) = ad - bc\n",
    "$$\n",
    "\n",
    "Now compute the determinant of the following matrix, and determine if this matrix is invertible or not\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "1 & -2 \\\\\n",
    "2 & -4 \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966a546-c03a-4c48-9d0a-4dfa67fb2a6c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix determinant for a 3x3 matrix\n",
    "\n",
    "For a 3x3 matrix, it is a little bit more complex. \n",
    "\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "a & b & c \\\\\n",
    "d & e & f \\\\\n",
    "g & h & i\n",
    "\\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ det(\\boldsymbol{A}) = (aei+dhc+gbf) - (efg+fha+ibd)\n",
    "$$\n",
    "\n",
    "Now compute the determinant of the following matrix, and determine if this matrix is invertible or not\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "1 & -2 & 0 \\\\\n",
    "2 & 1 & -2\\\\\n",
    "0 & -2 & 1\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600272c-63c9-40a2-830d-270371e40b36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Finding inverse of matrix 2x2 matrix\n",
    "\n",
    "For a 2x2 matrix $\\boldsymbol{A}$, its inverse $\\boldsymbol{A}^{-1}$ is easy to find\n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "a & b \\\\\n",
    "c & d \\end{bmatrix} \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol{A}^{-1} = \\frac{1}{det(\\boldsymbol{A})}\\begin{bmatrix} \n",
    "d & -c \\\\\n",
    "-b & a \\end{bmatrix} = \\frac{1}{ad-bc}\\begin{bmatrix} \n",
    "d & -b \\\\\n",
    "-c & a \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4752b9-340e-4644-a4ad-d76154d24490",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Finding inverse of matrix using minor, cofactor and adjugate\n",
    "\n",
    "The first step for finding the inverse of the matrix is to find its **minor matrix** $\\boldsymbol{M}$. \n",
    "\n",
    "How?\n",
    "\n",
    "For each entry $a_{ij}$ in the matrix $\\boldsymbol{A}$, the minor for this entry is the determinant of the matrix after removing the $i$th row and the $j$th column. \n",
    "\n",
    "![matrix_inverse](./img/matrix_minors1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aadbbd-7edc-4558-89cf-7337bb7f928c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Cofactor matrix\n",
    "\n",
    "After found the minor matrix for matrix $\\boldsymbol{A}$, the next step is to find its cofactor matrix $\\boldsymbol{C}$.\n",
    "\n",
    "The cofactor matrix is by changing the sign of the entries in the minor matrix by multiplying $(-1)^{i+j}$ to the entry $m_{ij}$ in the minor matrix $\\boldsymbol{M}$, such that $c_{ij} = (-1)^{i+j}m_{ij}$\n",
    "\n",
    "You can also check the checkerboard for determining sign of entries in the cofactor matrix.\n",
    "\n",
    "![matrix_inverse](./img/matrix_cofactor.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce87d54-0d9f-467e-b6ef-881779757687",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Adjugate matrix and the inverse matrix\n",
    "\n",
    "The adjugate matrix is just the transpose of the cofactor matrix $\\boldsymbol{C}^T$.\n",
    "\n",
    "And the last step is to multiply the adjugate matrix with the inverse of the determinant of the matrix $\\frac{1}{det(\\boldsymbol{A})}$. \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A}^{-1} = \\frac{1}{det(\\boldsymbol{A})} \\boldsymbol{C}^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a51cf3-9ec9-4091-ab42-4f230e3508f3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Matrix inverse practice\n",
    "\n",
    "Compute the inverse of the following matrix \n",
    "\n",
    "$$\n",
    "\\boldsymbol{A} = \\begin{bmatrix} \n",
    "1 & -2 & 0 \\\\\n",
    "2 & 1 & -2\\\\\n",
    "0 & -2 & 1\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dad0c4-d19d-4916-9ff0-302d64523797",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "slides"
    ]
   },
   "source": [
    "## Rules of matrix inverse\n",
    "\n",
    "1. If $\\boldsymbol{A}$ is symmetric, then $\\boldsymbol{A}^{-1}$ is also symmetric.\n",
    "2. The inverse of matrix transpose is the transpose of the inverse $(\\boldsymbol{A}^T)^{-1} = (\\boldsymbol{A}^{-1})^T$\n",
    "3. The inverse of the matrices product is the product of matrices inverse in opposite direction.\n",
    "   $$\n",
    "   (\\boldsymbol{A}\\boldsymbol{B})^{-1} = \\boldsymbol{B}^{-1}\\boldsymbol{A}^{-1}\n",
    "   $$\n",
    "   $$\n",
    "   (\\boldsymbol{A}\\boldsymbol{B}\\boldsymbol{C})^{-1} = \\boldsymbol{C}^{-1}\\boldsymbol{B}^{-1}\\boldsymbol{A}^{-1}\n",
    "   $$\n",
    "4. The inverse of scalar times a matrix is the scaler inverse times the matrix inverse\n",
    "   $$\n",
    "   (c\\boldsymbol{A})^{-1} = \\frac{1}{c}\\boldsymbol{A}^{-1}\n",
    "   $$\n",
    "5. The inverse of a digonal matrix is also a digonal matrix with its digonal entries being inversed.\n",
    "   $$\n",
    "    (\\begin{bmatrix} \n",
    "a_{1} & ... & 0 \\\\\n",
    "... & ... & ...\\\\\n",
    "0 & ... & a_{u}\\end{bmatrix})^{-1} = \\begin{bmatrix} \n",
    "1/a_{1} & ... & 0 \\\\\n",
    "... & ... & ...\\\\\n",
    "0 & ... & 1/a_{u}\\end{bmatrix}\n",
    "   $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
